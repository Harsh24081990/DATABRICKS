Sure! Hereâ€™s a **simple and complete Databricks example** of how to implement **SCD Type 1 (Slowly Changing Dimension Type 1)** using **Delta Lake `MERGE INTO`** statements.

---

### ğŸ§  **What is SCD Type 1?**

SCD Type 1 **overwrites** old data with the latest dataâ€”**no history is preserved**. Itâ€™s used when tracking changes isn't important.

---

### âœ… **Step-by-Step: Implementing SCD Type 1 in Databricks with Delta**

---

### ğŸ”¹ 1. **Create Sample Source Data (Latest Updates)**

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import lit

# Sample source data
source_data = [
    (1, "Alice", "New York"),          # No change
    (2, "Bob", "San Diego"),           # City changed
    (3, "Charlie", "Chicago")          # New record
]

source_df = spark.createDataFrame(source_data, ["ID", "Name", "City"])
source_df.createOrReplaceTempView("source")
```

---

### ğŸ”¹ 2. **Create Initial Target Table**

```python
# Initial target table with existing records
target_data = [
    (1, "Alice", "New York"),
    (2, "Bob", "Los Angeles")
]

target_df = spark.createDataFrame(target_data, ["ID", "Name", "City"])

# Save as a Delta table
target_df.write.format("delta").mode("overwrite").saveAsTable("target")
```

---

### ğŸ” 3. **Perform SCD Type 1 Merge (Overwrite Existing Data)**

```sql
MERGE INTO target AS tgt
USING source AS src
ON tgt.ID = src.ID

-- If record exists and has changes, update
WHEN MATCHED THEN
  UPDATE SET tgt.Name = src.Name,
             tgt.City = src.City

-- If record doesnâ€™t exist, insert it
WHEN NOT MATCHED THEN
  INSERT (ID, Name, City)
  VALUES (src.ID, src.Name, src.City);
```

---

### ğŸ” 4. **View Final Result**

```sql
SELECT * FROM target ORDER BY ID;
```

---

### âœ… Output After Merge

| ID | Name    | City       |
|----|---------|------------|
| 1  | Alice   | New York   | âœ… No change  
| 2  | Bob     | San Diego  | âœ… City updated (overwrite)
| 3  | Charlie | Chicago    | âœ… New record inserted

---

### ğŸ’¡ Notes:
- No `IsCurrent`, `StartDate`, `EndDate`â€”because history isnâ€™t stored in Type 1.
- Great for attributes like `Email`, `Phone`, or `Name` when historical tracking isnâ€™t needed.

---

Let me know if you'd like this wrapped in a **Databricks notebook**, or need a version using **PySpark instead of SQL**!
